---
layout: default
title: Sparse coded word representations
---
<div class="blurb">
    <h1>Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling</h1>
    <p>This page contains the sparse word representations used for the experiments of the TACL paper entitled <i>Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling</i>.</p>

    <p>We determined <i>sparse</i> word representations based on the dense distributed word representations of the <a href="https://sites.google.com/site/rmyeid/projects/polyglot">polyglot project</a> using the objective function</p>
    $$\min\limits_{D \in \mathcal{C}, \alpha} \frac{1}{2n} \sum_{i=1}^{n} \left(\lVert \mathbf{x}_i-D \boldsymbol{\alpha}_i \rVert_2^2 + \lambda \lVert \boldsymbol{\alpha}_i \rVert_1 \right),$$
    <p>where $D$ belongs to the convex set of matrices comprising of unit vectors, $\mathbf{x}_i$ refers to a dense polyglot word representation and $\boldsymbol{\alpha}_i$ corresponds to its sparse counterpart. The files below contain a <tt>scipy.sparse.csr_matrix</tt> object storing an $\alpha \in \mathbb{R}^{\lVert V \rVert \times 1024}$ sparse matrix for each language (with $\lvert V \rvert$ denoting the size of the vocabulary).</p>
    
    <p>The vocabulary for each language is tied to that of the original polyglot representations, so in order to figure out which row of $\alpha$ corresponds to which vocabulary unit, one should obtain the original polyglot vocabularies. The vocabularies can be downloaded from the <a href="https://sites.google.com/site/rmyeid/projects/polyglot#TOC-Download-the-Embeddings">project website</a> (together with the dense embeddings themselves). Loading the vocabulary and both the sparse and dense embeddings thus can be performed via:</p>
    {% highlight python %}
    import pickle
    vocabulary, dense_polyglot_embeddings = pickle.load(open(path_to_dense_polyglot_embeddings, 'rb'))
    sparse_embeddings = pickle.load(open(path_to_alphas_file, 'rb'))
    {% endhighlight %}
    <table>
        <tr>
            <th>Wikipedia language code</th>
            <th>$\lambda=0.05$</th>
            <th>$\lambda=0.1$</th>
            <th>$\lambda=0.2$</th>
            <th>$\lambda=0.3$</th>
            <th>$\lambda=0.4$</th>
            <th>$\lambda=0.5$</th>
        </tr>
        {% assign languages = "bg,cs,da,de,el,en,es,et,eu,fa,fi,fr,ga,he,hi,hr,hu,id,it,la,nl,no,pl,pt,ro,sl,sv,ta,tr" | split: "," %}
        {% assign conllx_languages = "bg,da,de,en,es,hu,it,nl,pt,sl,sv,tr" | split: "," %}
        {% for l in languages %}
        <tr>
            <td>{{ l }}</td>
            <td>
            {% if conllx_languages contains l %}
            <a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps/{{ l }}-1024-0.05.alph">{{ l }}-0.05</a></td>
            {% else %}
            ---
            {% endif %}
            </td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps/{{ l }}-1024-0.1.alph">{{ l }}-0.1</a></td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps/{{ l }}-1024-0.2.alph">{{ l }}-0.2</a></td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps/{{ l }}-1024-0.3.alph">{{ l }}-0.3</a></td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps/{{ l }}-1024-0.4.alph">{{ l }}-0.4</a></td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps/{{ l }}-1024-0.5.alph">{{ l }}-0.5</a></td>
        </tr>
        {% endfor %}
    </table>

    <p>We also created word representations using the objective functions introduced by <a href="https://aclweb.org/anthology/P/P15/P15-1144.pdf">Faruqui et al. (2015).</a> This approach comes in two flavors (using an unconstrained and a non-negativity constrained objective function). For more details please refer to the paper.</p>
 <table>
        <tr>
            <th>Wikipedia language code</th>
            <th>uncostrained</th>
            <th>non-negative</th>
        </tr>
        {% assign languages = "bg,cs,da,de,el,en,es,et,eu,fa,fi,fr,ga,he,hi,hr,hu,id,it,la,nl,no,pl,pt,ro,sl,sv,ta,tr" | split: "," %}
        {% for l in languages %}
        <tr>
            <td>{{ l }}</td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps_unc/{{ l }}-1024-0.5.alph">{{ l }}-0.5</a></td>
            <td><a href="http://rgai.inf.u-szeged.hu/~berend/sparse_reps_nn/{{ l }}-1024-0.5.alph">{{ l }}-0.5</a></td>
        </tr>
        {% endfor %}
    </table>
</div>
