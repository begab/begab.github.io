---
layout: default
title: Sparse coded word representations
---
<div class="blurb">
    <h1>Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling</h1>
    $$\min\limits_{D \in \mathcal{C}, \alpha} \frac{1}{2n} \sum_{i=1}^{n} \left(\lVert \mathbf{x}_i-D \boldsymbol{\alpha}_i \rVert_2^2 + \lambda \lVert \boldsymbol{\alpha}_i \rVert_1 \right)$$

    <a href="https://sites.google.com/site/rmyeid/projects/polyglot">polyglot</a>
    
    Each of the below files store the $\alpha \in \mathbb{R}^{|V| \times 1024}$ matrix in scipy.sparse.csr_matrix format for each language (with $\lvert V \rvert$ denoting the size of the vocabulary).
    {% highlight python %}
    import pickle
    alphas_file = 'en.alph'
    english_alphas = pickle.load(open(alphas_file, 'rb'))
    {% endhighlight %}
    <ul>
        {% assign languages = "bg,cs,da,de,el,en,es,et,eu,fa,fi,fr,ga,he,hi,hr,hu,id,it,la,nl,no,pl,pt,ro,sl,sv,ta,tr" | split: "," %}
        {% for l in languages %}
        <li><a href="https://github.com/begab/begab.github.io/raw/master/sparse_embeds/{{ l }}.alph">{{ l }}</a></li>
        {% endfor %}
    </ul>
</div>
